{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='table_of_contents'></a>\n",
    "\n",
    "# Table of Contents\n",
    "&emsp; [Import Libraries](#import_libraries) <br> <br>\n",
    "&emsp; [Load Data](#load_data) <br> <br>\n",
    "[1. Data Understanding & Feature Analysis](#data_understanding_feature_analysis) <br> <br>\n",
    "&emsp; [1.1 Visualization](#visualization) <br> <br>\n",
    "&emsp; [1.2 Feature Analysis](#feature_analysis) <br> <br>\n",
    "[2. Data Wrangling & Preprocessing](#data_wrangling_preprocessing) <br> <br>\n",
    "&emsp; [2.1 Bryan Ling Zehao](#bryan_ling_zehao) <br> <br>\n",
    "&emsp; &emsp; [2.11 Remove Unwanted Columns](#remove_unwanted_columns_bryan) <br> <br>\n",
    "&emsp; &emsp; [2.12 Handle Missing Values](#handle_missing_values_bryan) <br> <br>\n",
    "&emsp; &emsp; [2.13 Categorical Data Encoding](#categorical_data_encoding_bryan) <br> <br>\n",
    "&emsp; &emsp; [2.14 Data Imputation](#data_imputation_bryan) <br> <br>\n",
    "&emsp; &emsp; [2.15 Feature Selection](#feature_selection_bryan) <br> <br>\n",
    "&emsp; [2.2 Chai Xiang Zhi](#chai_xiang_zhi) <br> <br>\n",
    "&emsp; &emsp; [2.21 Feature Imputation](#feature_imputation_xz) <br> <br>\n",
    "&emsp; &emsp; [2.22 Feature Binning & Discretisation](#feature_binning_and_discretisation_xz) <br> <br>\n",
    "&emsp; &emsp; [2.23 Feature Engineering & Combination](#feature_engineering_and_combination_xz) <br> <br>\n",
    "&emsp; &emsp; [2.24 Drop Features](#drop_featues_xz) <br> <br>\n",
    "&emsp; &emsp; [2.25 Datatype Transformation](#datatype_transformation_xz) <br> <br>\n",
    "&emsp; &emsp; [2.26 Numerical Feature Normalisation](#numerical_feature_normalisation_xz) <br> <br>\n",
    "&emsp; &emsp; [2.27 Categorical Feature Encoding](#categorical_feature_encoding_xz) <br> <br>\n",
    "[3. Exploratory Data Analysis (EDA)](#eda) <br> <br>\n",
    "[4. Model Development](#model_development) <br> <br>\n",
    "&emsp; [4.1 Baseline Models Overview](#baseline_models_overview) <br> <br>\n",
    "&emsp; [4.2 Hyperparameter Tuning](#hyperparameter_tuning) <br> <br>\n",
    "[5. Model Evaluation](#model_evaluation) <br> <br>\n",
    "&emsp; [5.1 K-fold Cross Validation](#k_fold_cross_validation) <br> <br>\n",
    "&emsp; [5.2 F1 Score](#f1_score) <br> <br>\n",
    "&emsp; [5.3 Confusion Matrix](#confusion_matrix) <br> <br>\n",
    "&emsp; [5.4 ROC](#roc) <br> <br>\n",
    "[6. Model Deployment](#model_deployment) <br> <br>\n",
    "&emsp; [6.1 Final Modelling using entire Training Dataset](#f) <br> <br>\n",
    "&emsp; [6.2 Predict Test Set](#f) <br> <br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='import_libraries'></a>\n",
    "## Import Libraries\n",
    "\n",
    "###### &emsp; &emsp; &emsp; &nbsp; &nbsp;[Table of Contents](#table_of_contents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### &emsp; &emsp; Data Understanding and Feature Analysis Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data visualisation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Features summary\n",
    "from fast_ml import eda\n",
    "from fast_ml.utilities import display_all\n",
    "\n",
    "# Missing data visualisation\n",
    "import missingno as msno"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### &emsp; &emsp; Data Preprocessing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multivariaate feature imputation method\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Categorical feature encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Feature selection\n",
    "from sklearn.feature_selection import chi2, f_classif, mutual_info_classif, RFE\n",
    "\n",
    "# Feature binning on funder & installer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "# Numerical feature normalisation\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### &emsp; &emsp; Modelling & Model Evaluation Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelling\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Model saving\n",
    "import pickle\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, classification_report, ConfusionMatrixDisplay, accuracy_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='load_data'></a>\n",
    "## Load Data\n",
    "###### &emsp; &emsp; &emsp; &nbsp; &nbsp;[Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the training set for each member of the group\n",
    "df_xz = pd.read_csv('./dataset/data_mining_water_table.csv')\n",
    "df_bryan = pd.read_csv('./dataset/data_mining_water_table.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='data_understanding_feature_analysis'></a>\n",
    "# 1. Data Understanding & Feature Analysis\n",
    "###### &emsp; &emsp; &emsp; &nbsp; &nbsp;[Table of Contents](#table_of_contents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='data_wrangling_preprocessing'></a>\n",
    "# 2. Data Wrangling & Preprocessing\n",
    "###### &emsp; &emsp; &emsp; &nbsp; &nbsp;[Table of Contents](#table_of_contents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='bryan_ling_zehao'></a>\n",
    "## &emsp; 2.1 Bryan Ling Zehao\n",
    "###### &emsp; &emsp; &emsp; &nbsp; &nbsp;[Table of Contents](#table_of_contents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='remove_unwanted_columns_bryan'></a>\n",
    "### &emsp; &emsp; 2.11 Remove Unwanted Columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='handle_missing_values_bryan'></a>\n",
    "### &emsp; &emsp; 2.12 Handle Missing Values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='categorical_data_encoding_bryan'></a>\n",
    "### &emsp; &emsp; 2.13 Categorical Data Encoding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data_imputation_bryan'></a>\n",
    "### &emsp; &emsp; 2.14 Data Imputation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='feature_selection_bryan'></a>\n",
    "### &emsp; &emsp; 2.15 Feature Selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='chai_xiang_zhi'></a>\n",
    "## &emsp; 2.2 Chai Xiang Zhi\n",
    "###### &emsp; &emsp; &emsp; &nbsp; &nbsp;[Table of Contents](#table_of_contents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='feature_imputation_xz'></a>\n",
    "### &emsp; &emsp; 2.21 Feature Imputation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='feature_binning_and_discretisation_xz'></a>\n",
    "### &emsp; &emsp; 2.22 Feature Binning & Discretisation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='feature_engineering_and_combination_xz'></a>\n",
    "### &emsp; &emsp; 2.23 Feature Engineering & Combination"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='drop_featues_xz'></a>\n",
    "### &emsp; &emsp; 2.24 Drop Features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='datatype_transformation_xz'></a>\n",
    "### &emsp; &emsp; 2.25 Datatype Transformation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='numerical_feature_normalisation_xz'></a>\n",
    "### &emsp; &emsp; 2.26 Numerical Feature Normalisation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='categorical_feature_encoding_xz'></a>\n",
    "### &emsp; &emsp; 2.27 Categorical Feature Encoding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='eda'></a>\n",
    "# 3. Exploratory Data Analysis (EDA)\n",
    "###### &emsp; &emsp; &emsp; &nbsp; &nbsp;[Table of Contents](#table_of_contents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='model_development'></a>\n",
    "# 4. Model Development\n",
    "###### &emsp; &emsp; &emsp; &nbsp; &nbsp;[Table of Contents](#table_of_contents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='baseline_models_overview'></a>\n",
    "## &emsp; 4.1 Baseline Models Overview"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='hyperparameter_tuning'></a>\n",
    "## &emsp; 4.2 Hyperparameter tuning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='model_evaluation'></a>\n",
    "# 5. Model Evaluation\n",
    "###### &emsp; &emsp; &emsp; &nbsp; &nbsp;[Table of Contents](#table_of_contents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='k_fold_cross_validation'></a>\n",
    "## &emsp; 5.1 K-fold Cross Validation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='f1_score'></a>\n",
    "## &emsp; 5.2 F1 Score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='confusion_matrix'></a>\n",
    "## &emsp; 5.3 Confusion Matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='roc'></a>\n",
    "## &emsp; 5.4 ROC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='model_deployment'></a>\n",
    "# 6. Model Deployment\n",
    "\n",
    "\n",
    "###### &emsp; &emsp; &emsp; &nbsp; &nbsp;[Table of Contents](#table_of_contents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
